好的，这是移除了 "如何使用 (示例)" 和 "引用" 部分的 README。Learning Complementary Biomarkers: 2.5D ViT and Aβ-PET/Tau-PET Cross-Attention Fusion for CDR-level Alzheimer’s ClassificationThis project implements the models described in the paper "Learning Complementary Biomarkers: 2.5D ViT and Cross-Attention Fusion of Amyloid-PET and Tau-PET for CDR-level Alzheimer’s Classification".The goal of this project is to classify patient-level Alzheimer's status (CDR>0 vs CDR=0) using complementary Amyloid-PET (Aβ-PET) and Tau-PET signals.IntroductionAβ-PET and Tau-PET capture complementary biological information in Alzheimer's disease. This project aims to efficiently fuse these two modalities to classify cognitive impairment (CDR>0 vs CDR=0).The project addresses three main challenges:Data Efficiency: Handling the modest sample size of paired scan data.Leakage Prevention: Controlling data leakage by using strict patient-level splits.Interpretability: Understanding which slices and which biomarkers drive the model's predictions.Core Features2.5D ViT Model: A data-efficient 2.5D Vision Transformer (ViT) that encodes 2D axial slices and applies attention across the depth dimension1111.Cross-Attention Fusion: A lightweight fusion module that allows Aβ and Tau features to "query" each other222222222.Interpretability: The resulting slice-attention maps align with known biological patterns of Aβ (cortical) and Tau (medial-temporal)333333333.Model Architecture1. Unimodal 2.5D ViT EncoderEach PET volume (Aβ or Tau) is treated as a sequence of axial slices along the depth axis4.A pre-trained 2D ViT backbone encodes each individual 2D slice5.A multi-head self-attention block aggregates all slice features across the depth dimension to produce a single global representation6.2. Multimodal FusionDuring fusion training, the unimodal encoders remain frozen777777777. Two fusion strategies were compared:Baseline: Feature-concatenationThe global feature vectors from Aβ and Tau are simply concatenated and passed to a small MLP for classification8.Our Method: Cross-attentionBefore concatenation, the Aβ and Tau global feature vectors are processed by a cross-attention block, allowing the features to interact and query each other999999999.Dataset & PreprocessingData Source: ADNI 10Data Modalities: Amyloid-PET (Aβ) and Tau-PET 11Labels: Binary label based on global CDR score (y=1 if CDR>0, else 0) 12Data Split: Strict patient-level 80/20 stratified split 131313131313131313Preprocessing:Normalization: Per-scan min-max normalization to [0, 1] 14141414Resampling: Using SimpleITK with linear interpolation 15151515Target Grid (2.5D-ViT): (64, 224, 224) (i.e., 64 axial slices at 224x224) 16161616Main ResultsPerformance comparison on the paired validation set (N = 138)171717:Fusion StrategyAccuracyROC-AUCMacro-F1Feature Concatenation (Baseline)0.63 180.6764 190.61 20Cross-Attention (Our Method)0.7609 210.8341 220.7587 23
